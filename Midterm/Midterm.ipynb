{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Midterm\n",
    "\n",
    "**Course:** MATH 616 - Data-Driven Dynamical Systems, Stochastic Modeling and Prediction\n",
    "\n",
    "**Name:** Shrivats Sudhir\n",
    "\n",
    "**NetID:** ssudhir2\n",
    "\n",
    "**Email:** ssudhir2@wisc.edu\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.\n",
    "\n",
    "**Consider the following linear Gaussian SDE:**\n",
    "$$dx_t = -x_t\\;dt + dW_t, \\quad x_0=1$$\n",
    "\n",
    "We can re-write the above as:\n",
    "$$dx_t = (-a x_t + f_t) d_t + \\sigma dW_t$$\n",
    "\n",
    "where $a=1$, $f_t=0$ and $\\sigma=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a.)\n",
    "\n",
    "**Use the Euler-Maruyama method to create a numerical simulation. Plot a time series to illustrate the solution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dXt(Xt, dt, dWt):\n",
    "    \"\"\"\n",
    "    SDE function for the time derivative of Xt: dX_t = -X_t * dt + dW_t\n",
    "    \n",
    "    Parameters:\n",
    "    - Xt (float): The current value of the process Xt.\n",
    "    - dt (float): The time step size.\n",
    "    - dWt (float): The Wiener process increment (random term).\n",
    "    \n",
    "    Returns:\n",
    "    - (float): The time derivative of Xt based on the current value, time step size, and random increment.\n",
    "    \"\"\"\n",
    "    return -Xt * dt + dWt\n",
    "\n",
    "def euler_maruyama(T, N, X0):\n",
    "    \"\"\"\n",
    "    Euler-Maruyama method to numerically solve the stochastic differential equation (SDE):\n",
    "    dX_t = -X_t dt + dW_t, X_0 = X0\n",
    "    \n",
    "    Parameters:\n",
    "    - T (float): The total simulation time.\n",
    "    - N (int): The number of time steps.\n",
    "    - X0 (float): The initial value of the process Xt at time t=0.\n",
    "    \n",
    "    Returns:\n",
    "    - t (numpy.ndarray): Array of time points from 0 to T.\n",
    "    - Xt (numpy.ndarray): Array of simulated values of the process Xt at each time step.\n",
    "    \"\"\"\n",
    "    dt = T / N\n",
    "    t = np.linspace(0, T, N+1)\n",
    "    \n",
    "    Xt = np.zeros(N+1)\n",
    "    Xt[0] = X0  # Initial condition\n",
    "    \n",
    "    # Simulating the process using Euler-Maruyama\n",
    "    for i in range(1, N+1):\n",
    "        dWt = np.sqrt(dt) * np.random.normal(0, 1)  # Wiener process increment\n",
    "        Xt[i] = Xt[i-1] + dXt(Xt[i-1], dt, dWt)     # Euler-Maruyama scheme\n",
    "    \n",
    "    return t, Xt\n",
    "\n",
    "def statistics_TS(Xt):\n",
    "    \"\"\"\n",
    "    Calculate and print simple statistics for the time series Xt.\n",
    "    \n",
    "    Parameters:\n",
    "    - Xt (numpy.ndarray): Array of simulated values of the process Xt.\n",
    "    \n",
    "    Returns:\n",
    "    - mean_xt (float): The mean of the time series Xt.\n",
    "    - std_xt (float): The standard deviation of the time series Xt.\n",
    "    \"\"\"\n",
    "    mean_xt = np.mean(Xt)\n",
    "    std_xt = np.std(Xt)\n",
    "    var_xt = np.var(Xt)\n",
    "    max_xt = np.max(Xt)\n",
    "    min_xt = np.min(Xt)\n",
    "    \n",
    "    print(f\"Mean of X_t: {mean_xt:.4f}\")\n",
    "    print(f\"Standard Deviation of X_t: {std_xt:.4f}\")\n",
    "    print(f\"Variance of X_t: {var_xt:.4f}\")\n",
    "    print(f\"Max of X_t: {max_xt:.4f}\")\n",
    "    print(f\"Min of X_t: {min_xt:.4f}\")\n",
    "    \n",
    "    return mean_xt, std_xt\n",
    "\n",
    "# Run simulation and collect the respective t and Xt values\n",
    "T = 10              # Small total time\n",
    "N = 1000            # Number of steps\n",
    "X0 = 1              # Initial condition\n",
    "t, Xt = euler_maruyama(T=T, N=N, X0=0)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_xt, std_xt = statistics_TS(Xt)\n",
    "\n",
    "# Create the plot with explicit facecolor for axes\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "fig.patch.set_facecolor('white')  # Set the figure background to white\n",
    "ax.set_facecolor('white')         # Set the axis background to white\n",
    "\n",
    "ax.plot(t, Xt, alpha=0.5, color='black', label='Euler-Maruyama Simulation', linewidth=1)\n",
    "ax.axhline(y=mean_xt-std_xt, color=\"orange\", linestyle=\"--\", label=f\"standard deviation bands\")\n",
    "ax.axhline(y=mean_xt, color=\"black\", linestyle=\"--\", label=f\"Mean = {mean_xt:.4f}\")\n",
    "ax.axhline(y=mean_xt+std_xt, color=\"orange\", linestyle=\"--\")\n",
    "ax.set_title(f'Euler-Maruyama Simulation of SDE: $dX_t = -X_t dt + dW_t$, $X_0 = {0}$', fontsize=14)\n",
    "ax.set_xlabel('Time', fontsize=12)\n",
    "ax.set_ylabel('$X_t$', fontsize=12)\n",
    "ax.grid(True, color='black', alpha=0.1)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b.)\n",
    "\n",
    "**Using time series data from your numerical simulation, find a numerical estimate of $\\langle x_t^2 \\rangle$ in statistical equilibrium (for large time $t$).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we know that the long-run equilibrium solution of the mean and variance (6.2 Statistical Equilibrium State and Decorrelation Time) is given by:\n",
    "$$\\mu(x)_{\\infty} = \\frac{f}{a} = \\frac{0}{1} = 0$$\n",
    "$$\\text{Var}(x)_{\\infty} = \\frac{\\sigma^2}{2a} = \\frac{1^2}{2 \\cdot 1} = 0.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mean_var(Xt):\n",
    "    \"\"\"\n",
    "    Calculate the sample estimates of the first moment (mean) and the second moment \n",
    "    (not centralized) of the given time series Xt.\n",
    "    \n",
    "    Parameters:\n",
    "    - Xt (numpy.ndarray): Array of simulated values of the process Xt.\n",
    "\n",
    "    Returns:\n",
    "    - mean_xt (float): The first moment, i.e., the sample mean of Xt.\n",
    "    - second_moment_xt (float): The second moment (not centralized), i.e., the sample mean of Xt squared.\n",
    "    \"\"\"\n",
    "    return np.mean(Xt), np.mean(Xt**2)\n",
    "\n",
    "# Run simulation and collect the respective t and Xt values\n",
    "T = 10000           # Large total time\n",
    "N = 1000000         # Number of steps\n",
    "X0 = 1              # Initial condition\n",
    "t, Xt = euler_maruyama(T, N, X0)\n",
    "\n",
    "# Theoretical distribution\n",
    "mean, std = 0, np.sqrt(0.5)\n",
    "print(f\"Theoretical estimate of ⟨x_t⟩ in equilibrium: {0}\")\n",
    "print(f\"Numerical estimate of ⟨x_t^2⟩ in equilibrium: {0.5}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculate equilibrium (long-run) first moment and second moment (not centralized)\n",
    "x_mean_equilibrium, x_squared_mean_equilibrium = estimate_mean_var(Xt)\n",
    "print(f\"Numerical estimate of ⟨x_t⟩ in equilibrium: {x_mean_equilibrium:.4f}\")\n",
    "print(f\"Numerical estimate of ⟨x_t^2⟩ in equilibrium: {x_squared_mean_equilibrium:.4f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create figure with custom layout\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[4, 1], wspace=0.05)\n",
    "\n",
    "# Left subplot: Time series (larger)\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.plot(t, Xt, alpha=0.5, color='black', label='Euler-Maruyama Simulation', linewidth=1)\n",
    "ax1.axhline(y=x_mean_equilibrium, color=\"black\", linestyle='--', label=\"mean=0\")\n",
    "ax1.axhline(y=x_mean_equilibrium+np.sqrt(x_squared_mean_equilibrium), \n",
    "            color=\"orange\", linestyle=\"--\", label=\"standard deviation bands\")\n",
    "ax1.axhline(y=x_mean_equilibrium-np.sqrt(x_squared_mean_equilibrium), \n",
    "            color=\"orange\", linestyle=\"--\")\n",
    "ax1.set_title('Long-time Euler-Maruyama Simulation\\n$dX_t = -X_t dt + dW_t$, $X_0 = 1$', pad=10)\n",
    "ax1.set_xlabel('Time', fontsize=12)\n",
    "ax1.set_ylabel('$X_t$', fontsize=12)\n",
    "ax1.set_xlim(0, 10000)\n",
    "ax1.set_facecolor('white')\n",
    "ax1.grid(True, color='black', alpha=0.1)\n",
    "ax1.legend()\n",
    "\n",
    "# Right subplot: Rotated histogram\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.hist(Xt, bins=25, density=True, orientation='horizontal',\n",
    "         alpha=0.5, color='grey', label='Simulation')\n",
    "\n",
    "y = np.linspace(-3, 3, 100)\n",
    "pdf1 = norm.pdf(y, mean, std)\n",
    "ax2.plot(pdf1, y, alpha=0.5, color=\"red\", \n",
    "         linestyle='--', label='Theoretical: N(0, 0.5)')\n",
    "\n",
    "pdf2 = norm.pdf(y, x_mean_equilibrium, np.sqrt(x_squared_mean_equilibrium))\n",
    "ax2.plot(pdf2, y, alpha=0.5, color=\"blue\",\n",
    "         linestyle='--', label=f'Estimated: N({np.round(x_mean_equilibrium, 2)}, {np.round(x_squared_mean_equilibrium, 2)})')\n",
    "\n",
    "ax2.axhline(y=mean+std, color=\"orange\", linestyle=\"--\", label=\"standard deviation bands\")\n",
    "ax2.axhline(y=mean-std, color=\"orange\", linestyle=\"--\")\n",
    "ax2.axhline(y=0, color=\"black\", linestyle='--', label='mean')\n",
    "ax2.set_title('Density Distribution')\n",
    "ax2.set_xlabel('Density')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_facecolor('white')\n",
    "ax2.grid(True, color='black', alpha=0.1)\n",
    "ax2.legend()\n",
    "\n",
    "ylim = ax1.get_ylim()\n",
    "ax2.set_ylim(ylim)\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c.)\n",
    "\n",
    "**Using time series data from your numerical simulation, find a numerical estimate of the autocorrelation function, $R(s)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From definition 6.1, we know that the auto-correlation function $(ACF)$ is:\n",
    "$$R(s) = \\frac{\\mathbb{E}[(X_t - \\mu_{\\infty})(X_{t+s} - \\mu_{\\infty})]}{\\text{Var}(x)_{\\infty}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_autocorrelation(Xt, mean_inf, var_inf, max_lag):\n",
    "    \"\"\"\n",
    "    Calculate the sample estimates of the autocorrelation function for a given \n",
    "    time series Xt up to a specified maximum lag.\n",
    "    \n",
    "    The autocorrelation at lag s is estimated using the formula:\n",
    "    R[s] = sum((Xt[:N-s] - mean_inf) * (Xt[s:N] - mean_inf)) / var_inf\n",
    "    \n",
    "    Parameters:\n",
    "    - Xt (numpy.ndarray): Array of simulated values of the process Xt.\n",
    "    - mean_inf (float): The mean of the time series Xt (used to centralize the data).\n",
    "    - var_inf (float): The variance of the time series Xt (used to normalize the autocorrelation).\n",
    "    - max_lag (int): The maximum lag for which to compute the autocorrelation.\n",
    "    \n",
    "    Returns:\n",
    "    - lags (range): The range of lag values from 0 to max_lag.\n",
    "    - R (numpy.ndarray): Array of autocorrelation values for each lag from 0 to max_lag.\n",
    "    \"\"\"\n",
    "    N = len(Xt)\n",
    "    R = np.zeros(max_lag+1)\n",
    "\n",
    "    for s in range(max_lag+1):\n",
    "        R[s] = np.mean((Xt[:N-s] - mean_inf) * (Xt[s:N] - mean_inf)) / var_inf\n",
    "\n",
    "    return range(max_lag+1), R\n",
    "\n",
    "# Run simulation and collect the respective t and Xt values\n",
    "T = 10           # Large total time\n",
    "N = 1000         # Number of steps\n",
    "X0 = 1           # Initial condition\n",
    "t, Xt = euler_maruyama(T, N, X0)\n",
    "x_mean_equilibrium, x_squared_mean_equilibrium = estimate_mean_var(Xt)\n",
    "\n",
    "# Parameters for each subplot to create a 3-row, 2-column plot with different T and N\n",
    "T_values = [10, 100, 1000]          # Different time horizons\n",
    "N_values = [1000, 100000, 1000000]  # Different number of steps\n",
    "max_lags = [10, 1000, 5000]         # Different max lags\n",
    "X0 = 1                              # Initial condition\n",
    "\n",
    "# Create figure for the new layout with adjusted width ratios\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(15, 6), gridspec_kw={'width_ratios': [3, 1]})\n",
    "fig.subplots_adjust(hspace=0.7, wspace=0.15)\n",
    "\n",
    "# Loop through each row for different T, N, and max_lag values\n",
    "for i in range(3):\n",
    "    \n",
    "    # Run simulation with different T and N values\n",
    "    t, Xt = euler_maruyama(T=T_values[i], N=N_values[i], X0=X0)\n",
    "    x_mean_equilibrium, x_squared_mean_equilibrium = estimate_mean_var(Xt)\n",
    "\n",
    "    # Estimate auto-correlation for each combination\n",
    "    lags, correlations = estimate_autocorrelation(Xt=Xt, \n",
    "                                                  mean_inf=x_mean_equilibrium, \n",
    "                                                  var_inf=x_squared_mean_equilibrium, \n",
    "                                                  max_lag=max_lags[i])\n",
    "\n",
    "    # Plot the time series on the left column\n",
    "    axs[i, 0].plot(t, Xt, alpha=0.5, color='black', linewidth=1)\n",
    "    axs[i, 0].axhline(y=x_mean_equilibrium, color=\"black\", linestyle='--', label=f\"mean\")\n",
    "    axs[i, 0].axhline(y=x_mean_equilibrium+np.sqrt(x_squared_mean_equilibrium), \n",
    "                color=\"orange\", linestyle=\"--\", label=\"standard deviation bands\")\n",
    "    axs[i, 0].axhline(y=x_mean_equilibrium-np.sqrt(x_squared_mean_equilibrium), \n",
    "                color=\"orange\", linestyle=\"--\")\n",
    "    axs[i, 0].set_title(f'Euler-Maruyama Simulation\\nT={T_values[i]}, N={N_values[i]}', pad=10)\n",
    "    axs[i, 0].set_xlabel('Time', fontsize=12)\n",
    "    axs[i, 0].set_ylabel('$X_t$', fontsize=12)\n",
    "    axs[i, 0].grid(True, color='black', alpha=0.1)\n",
    "    axs[i, 0].set_facecolor('white')\n",
    "\n",
    "    # Plot the auto-correlation function on the right column\n",
    "    axs[i, 1].plot(lags, correlations, color='blue', label=\"R(s)\")\n",
    "    axs[i, 1].set_title(f'Autocorrelation (max lag = {max_lags[i]})')\n",
    "    axs[i, 1].set_xlabel('Lag', fontsize=12)\n",
    "    axs[i, 1].set_ylabel('Autocorrelation', fontsize=12)\n",
    "    axs[i, 1].grid(True, color='black', alpha=0.1)\n",
    "    axs[i, 1].set_facecolor('white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.\n",
    "\n",
    "**Consider the following ODE system:**\n",
    "\n",
    "$$\\frac{du_1}{dt} = -2u_1 + u_2 + 1$$\n",
    "$$\\frac{du_2}{dt} = 2u_1 - 3u_2 + 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a.)\n",
    "\n",
    "**Derive the analytic solution of this system using the eigen-decomposition method.**\n",
    "\n",
    "We can re-write the ODE system of equation as follows:\n",
    "$$\\frac{d\\mathbf{u}}{dt} = \\underbrace{\\begin{bmatrix} -2 & 1\\\\ 2 & -3 \\end{bmatrix}}_{=\\mathbf{A}} \\cdot \\underbrace{\\begin{bmatrix} u_1\\\\ u_2 \\end{bmatrix}}_{=\\mathbf{u}} + \\underbrace{\\begin{bmatrix} 1\\\\ 1 \\end{bmatrix}}_{=\\mathbf{b}}$$\n",
    "\n",
    "Now, in order to make the above ODE system homogenous:\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        0 &= \\begin{bmatrix} -2 & 1\\\\ 2 & -3 \\end{bmatrix} \\cdot \\begin{bmatrix} u^*_1\\\\ u^*_2 \\end{bmatrix} + \\begin{bmatrix} 1\\\\ 1 \\end{bmatrix}\\\\\n",
    "        \\\\\n",
    "        \\begin{bmatrix} -1\\\\ -1 \\end{bmatrix} &= \\begin{bmatrix} -2 & 1\\\\ 2 & -3 \\end{bmatrix} \\cdot \\begin{bmatrix} u^*_1\\\\ u^*_2 \\end{bmatrix}\\\\\n",
    "        \\\\\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "We can now solve for $u^*_1$ and $u^*_2$ simultaneously as:\n",
    "$$-1 = -2u^*_1 + u^*_2$$\n",
    "$$-1 = 2u^*_1 - 3u^*_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining matrix A\n",
    "A = np.array([[-2, 1], \n",
    "              [2, -3]])\n",
    "\n",
    "# Solving for u*1 and u*2\n",
    "u1, u2 = np.linalg.solve(A,  np.array([-1, -1]))\n",
    "print(f\"u*1 = {u1}, u*2 = {u2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a new variable $\\mathbf{v} = \\mathbf{u} - \\mathbf{u}^* = \\begin{bmatrix} u_1-1 \\\\ u_2-1 \\end{bmatrix}$, our homogenous ODE system in vector form can now be written as:\n",
    "$$\\frac{d\\mathbf{v}}{dt} + \\mathbf{\\tilde{A}}\\mathbf{v} = 0$$\n",
    "where $\\mathbf{\\tilde{A}} = -\\mathbf{A} = \\begin{bmatrix} 2 & -1\\\\ -2 & 3 \\end{bmatrix}$\n",
    "\n",
    "Now, we know that the eigenvalues of $\\mathbf{\\tilde{A}}$ can be computed as:\n",
    "$$\\mathbf{\\tilde{A}}\\mathbf{c} = \\lambda \\mathbf{c}$$\n",
    "\n",
    "which, in matrix form can be re-written as:\n",
    "$$\\mathbf{\\tilde{A}}\\mathbf{C} = \\mathbf{C} \\Lambda$$\n",
    "where $\\Lambda$ is the diagonal matrix containing eigenvalues, and $\\mathbf{C}$ is the matrix containing eigenvectors as columns.\n",
    "\n",
    "Finally, we conclude that:\n",
    "$$\\mathbf{\\tilde{A}} = \\mathbf{C} \\Lambda \\mathbf{C}^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tilde{A} = -A\n",
    "A_tilde = np.array([[2, -1], \n",
    "                    [-2, 3]])\n",
    "\n",
    "# Computing eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A_tilde)\n",
    "\n",
    "# Representing eigenvalues as a diagonal matrix\n",
    "L = np.diag(eigenvalues)\n",
    "\n",
    "# Representing eigenvectors as columns of a matrix\n",
    "C = eigenvectors\n",
    "\n",
    "print(\"eigenvalues as a diagonal matrix (lambda):\\n\", L)\n",
    "print('\\n')\n",
    "print(\"eigenvectors as columns of matrix (C):\\n\", C)\n",
    "print('\\n')\n",
    "print(\"Confirming eigen-decomposition procedure (A - C^-1 * L * C) ≈ 0:\\n\", A_tilde - (C @ L @ linalg.inv(C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we now have that:\n",
    "$$\\Lambda = \\begin{bmatrix} \\lambda_1 & 0\\\\ 0 & \\lambda_2 \\end{bmatrix} = \\begin{bmatrix} 1 & 0\\\\ 0 & 4 \\end{bmatrix}, C = \\begin{bmatrix} C_{00} & C_{01}\\\\ C_{10} & C_{11} \\end{bmatrix} = \\begin{bmatrix} -0.70710678 & 0.4472136\\\\ -0.70710678 & -0.89442719 \\end{bmatrix}$$\n",
    "\n",
    "which lets us write our homogenous ODE as:\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        0 &= \\frac{d\\mathbf{v}}{dt} + \\mathbf{\\tilde{A}}\\mathbf{v}\\\\\n",
    "        \\\\\n",
    "          &= \\frac{d\\mathbf{v}}{dt} + (\\mathbf{C} \\Lambda \\mathbf{C}^{-1})\\mathbf{v}\\\\\n",
    "        \\\\\n",
    "          &= \\mathbf{C}^{-1}\\frac{d\\mathbf{v}}{dt} + \\Lambda (\\mathbf{C}^{-1}\\mathbf{v})\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Now, suppose $\\mathbf{w} = \\mathbf{C}^{-1}\\mathbf{v}$, then our ODE can now bw written as:\n",
    "$$\\frac{d\\mathbf{w}}{dt} + \\Lambda \\mathbf{w} = 0$$\n",
    "\n",
    "As we know $\\Lambda$ is a diagonal matrix, we can look at each vector element $w_i$ and solve the respective ODE as follows:\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        0 &= \\frac{dw_i}{dt} + \\lambda_i w_i\\\\\n",
    "        \\\\\n",
    "        -\\lambda_i w_i &= \\frac{dw_i}{dt}\\\\\n",
    "        \\\\\n",
    "        -\\lambda_i d_t &= \\frac{1}{w_i} dw_i\\\\\n",
    "        \\\\\n",
    "        \\int -\\lambda_i d_t &= \\int \\frac{1}{w_i} dw_i\\\\\n",
    "        \\\\\n",
    "        k_i \\cdot \\text{exp}(-\\lambda_i t) &= w_i\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore, we can re-write vector $\\mathbf{w}$ as follows:\n",
    "$$\\mathbf{w} = \\begin{bmatrix} k_1 \\cdot \\text{exp}(-\\lambda_1 t)\\\\ k_2 \\cdot \\text{exp}(-\\lambda_2 t) \\end{bmatrix}$$\n",
    "\n",
    "Substituting the eigenvalues $\\lambda_1=1$ and $\\lambda_2=4$, we have that:\n",
    "$$\\mathbf{w} = \\begin{bmatrix} k_1 \\cdot \\text{exp}(-t)\\\\ k_2 \\cdot \\text{exp}(-4t) \\end{bmatrix}$$\n",
    "\n",
    "Now, as $\\mathbf{w} = \\mathbf{C}^{-1}\\mathbf{v} \\iff \\mathbf{C} \\mathbf{w} = \\mathbf{v}$, we have that:\n",
    "$$\\mathbf{v} = \\begin{bmatrix} C_{00} & C_{01}\\\\ C_{10} & C_{11} \\end{bmatrix} \\cdot \\begin{bmatrix} k_1 \\cdot \\text{exp}(-t)\\\\ k_2 \\cdot \\text{exp}(-4t) \\end{bmatrix} = \\begin{bmatrix} C_{00} \\cdot k_1 \\cdot \\text{exp}(-t) + C_{01} \\cdot k_2 \\cdot \\text{exp}(-4t)\\\\ C_{10} \\cdot k_1 \\cdot \\text{exp}(-t) + C_{11} \\cdot k_2 \\cdot \\text{exp}(-4t) \\end{bmatrix}$$\n",
    "\n",
    "Finally, as $\\mathbf{u} = \\mathbf{u} - \\mathbf{u}^* \\iff \\mathbf{v} + \\mathbf{u}^* = \\mathbf{u}$, we have that:\n",
    "$$\\mathbf{u} = \\begin{bmatrix} C_{00} \\cdot k_1 \\cdot \\text{exp}(-t) + C_{01} \\cdot k_2 \\cdot \\text{exp}(-4t) + 1\\\\ C_{10} \\cdot k_1 \\cdot \\text{exp}(-t) + C_{11} \\cdot k_2 \\cdot \\text{exp}(-4t) + 1 \\end{bmatrix}$$\n",
    "\n",
    "In other words, the analytical solution of the ODE is:\n",
    "$$u_1 = C_{00} \\cdot k_1 \\cdot \\text{exp}(-t) + C_{01} \\cdot k_2 \\cdot \\text{exp}(-4t) + 1$$\n",
    "$$u_2 = C_{10} \\cdot k_1 \\cdot \\text{exp}(-t) + C_{11} \\cdot k_2 \\cdot \\text{exp}(-4t) + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u1(k1, k2, t):\n",
    "    \"\"\"\n",
    "    Analytical solution for u1, given constants k1, k2, and time t:\n",
    "    \n",
    "    u1 = C_00 * K_1 * exp(-t) + C_01 * K_2 * exp(-4t) + 1\n",
    "    \n",
    "    Parameters:\n",
    "    - k1 (float): A constant related to the initial conditions or parameters of the system.\n",
    "    - k2 (float): A constant related to the initial conditions or parameters of the system.\n",
    "    - t (float): Time variable.\n",
    "    \n",
    "    Returns:\n",
    "    - (float): The analytical solution for u1 at time t.\n",
    "    \"\"\"\n",
    "    return C[0][0] * k1 * np.exp(-t) + C[0][1] * k2 * np.exp(-4*t) + 1\n",
    "\n",
    "def u2(k1, k2, t):\n",
    "    \"\"\"\n",
    "    Analytical solution for u2, given constants k1, k2, and time t:\n",
    "    \n",
    "    u2 = C_10 * K_1 * exp(-t) + C_11 * K_2 * exp(-4t) + 1\n",
    "    \n",
    "    Parameters:\n",
    "    - k1 (float): A constant related to the initial conditions or parameters of the system.\n",
    "    - k2 (float): A constant related to the initial conditions or parameters of the system.\n",
    "    - t (float): Time variable.\n",
    "    \n",
    "    Returns:\n",
    "    - (float): The analytical solution for u2 at time t.\n",
    "    \"\"\"\n",
    "    return C[1][0] * k1 * np.exp(-t) + C[1][1] * k2 * np.exp(-4*t) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b.)\n",
    "\n",
    "**Then use forward Euler numerical scheme to validate your solution. In the numerical validation, you may choose the initial values to be $u_{1}(0) = 0.5$, $u_{2}(0) = 1.5$ and the final time $T = 5$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $u_1(0)=0.5$, $C_{00}=-0.70710678$, and $C_{10}=0.4472136$, we have that:\n",
    "$$-0.70710678 \\cdot k_1 + 0.4472136 \\cdot k_2 = -0.5$$\n",
    "\n",
    "Given $u_2(0)=5$, $C_{10}=-0.70710678$, and $C_{11}=-0.89442719$, we have that:\n",
    "$$-0.70710678 \\cdot k_1 - 0.89442719 \\cdot k_2 = 0.5$$\n",
    "\n",
    "We can solve the equations simulatenously to derive the constants $k_1$ and $k_2$ resepctively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving for constants k1 and k2\n",
    "k1, k2 = np.linalg.solve(C,  np.array([-0.5, 0.5]))\n",
    "print(f\"k1 = {k1}, k2 = {k2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def du1_dt(u1, u2):\n",
    "    \"\"\"\n",
    "    ODE function for the time derivative of u1: u1' = -2*u1 + u2 + 1\n",
    "    \n",
    "    Parameters:\n",
    "    - u1 (float): The current value of u1.\n",
    "    - u2 (float): The current value of u2.\n",
    "    \n",
    "    Returns:\n",
    "    - (float): The time derivative of u1 based on the current values of u1 and u2.\n",
    "    \"\"\"\n",
    "    return (-2*u1 + u2 + 1)\n",
    "\n",
    "def du2_dt(u1, u2):\n",
    "    \"\"\"\n",
    "    ODE function for the time derivative of u2: u2' = 2*u1 - 3*u2 + 1\n",
    "    \n",
    "    Parameters:\n",
    "    - u1 (float): The current value of u1.\n",
    "    - u2 (float): The current value of u2.\n",
    "\n",
    "    Returns:\n",
    "    - (float): The time derivative of u2 based on the current values of u1 and u2.\n",
    "    \"\"\"\n",
    "    return (2*u1 - 3*u2 + 1)\n",
    "\n",
    "def forward_euler(u10, u20, t0, tend, h):\n",
    "    \"\"\"\n",
    "    Forward Euler method to numerically solve the system of ODEs.\n",
    "\n",
    "    Parameters:\n",
    "    - u10 (float): The initial value of u1 at time t0.\n",
    "    - u20 (float): The initial value of u2 at time t0.\n",
    "    - t0 (float): The initial time.\n",
    "    - tend (float): The end time for the simulation.\n",
    "    - h (float): The time step size.\n",
    "\n",
    "    Returns:\n",
    "    - t (numpy.ndarray): Array of time points from t0 to tend.\n",
    "    - y (numpy.ndarray): Array of solutions, where each row contains the values [u1, u2] at the corresponding time point.\n",
    "    \"\"\"\n",
    "    num_steps = int((tend - t0) / h)\n",
    "    t = np.linspace(t0, tend, num_steps + 1)\n",
    "    y = np.zeros((num_steps + 1, 2))\n",
    "    y[0] = np.array([u10, u20])\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        u1, u2 = y[i]\n",
    "        y[i + 1] = np.array([\n",
    "            u1 + h * du1_dt(u1=u1, u2=u2),\n",
    "            u2 + h * du2_dt(u1=u1, u2=u2)\n",
    "        ])\n",
    "    \n",
    "    return t, y\n",
    "\n",
    "# Create figure plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Define h_values and color schema\n",
    "h_values = np.linspace(0.4, 0.001, 10)\n",
    "colors = plt.cm.inferno(np.linspace(0, 1, len(h_values)))\n",
    "\n",
    "# Get analytical solution\n",
    "t_analytical = np.linspace(0, 5, 1000)\n",
    "u1_analytical = [u1(k1, k2, t) for t in t_analytical]\n",
    "u2_analytical = [u2(k1, k2, t) for t in t_analytical]\n",
    "\n",
    "# Initial conditions\n",
    "u10 = u1(k1=k1, k2=k2, t=0)\n",
    "u20 = u2(k1=k1, k2=k2, t=0)\n",
    "\n",
    "# Plot Euler Approximations\n",
    "for i, h in enumerate(h_values):\n",
    "    t_numerical, y_numerical = forward_euler(u10, u20, t0=0, tend=5, h=h)\n",
    "    ax1.plot(t_numerical, y_numerical[:, 0], \n",
    "             marker='o', markersize=3, color=colors[i], alpha=0.7)\n",
    "    ax2.plot(t_numerical, y_numerical[:, 1], \n",
    "             marker='o', markersize=3, color=colors[i], alpha=0.7)\n",
    "\n",
    "# Plot analytical solutions\n",
    "ax1.plot(t_analytical, u1_analytical, '--', \n",
    "         color='red', linewidth=2, label='Analytical Solution')\n",
    "ax2.plot(t_analytical, u2_analytical, '--', \n",
    "         color='red', linewidth=2, label='Analytical Solution')\n",
    "\n",
    "# Plot elements\n",
    "fig.suptitle('Forward Euler Method: Euler Approximation vs Analytical Solutions', \n",
    "             fontsize=14, y=1.02)\n",
    "ax1.set_title('First Component ($u_1$)', fontsize=12)\n",
    "ax2.set_title('Second Component ($u_2$)', fontsize=12)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlabel('Time (t)', fontsize=10)\n",
    "    ax.set_ylabel('Solution Value', fontsize=10)\n",
    "    ax.grid(True)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.legend()\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap='inferno_r', norm=plt.Normalize(vmin=h_values.min(), vmax=h_values.max()))\n",
    "cbar = fig.colorbar(sm, ax=[ax1, ax2])\n",
    "cbar.set_label('Step Size (h)', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the phase plot with vector arrows\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Define grid points for vector field\n",
    "u1_vals = np.linspace(0.5, 1.2, 20)\n",
    "u2_vals = np.linspace(0.5, 1.5, 20)\n",
    "\n",
    "U1, U2 = np.meshgrid(u1_vals, u2_vals)\n",
    "dU1 = du1_dt(U1, U2)\n",
    "dU2 = du2_dt(U1, U2)\n",
    "\n",
    "# Plot vector field (direction arrows)\n",
    "ax.quiver(U1, U2, dU1, dU2, color='gray', alpha=0.6)\n",
    "\n",
    "# Plot Euler approximations for different step sizes\n",
    "for i, h in enumerate(h_values):\n",
    "    t_numerical, y_numerical = forward_euler(u10, u20, t0=0, tend=5, h=h)\n",
    "    ax.plot(y_numerical[:, 0], y_numerical[:, 1], \n",
    "            marker='o', markersize=3, color=colors[i], alpha=0.7)\n",
    "\n",
    "# Plot analytical phase trajectory\n",
    "ax.plot(u1_analytical, u2_analytical, \n",
    "        linestyle='--', color='red', linewidth=2, label='Analytical Solution')\n",
    "\n",
    "# Plot settings\n",
    "ax.set_title('Phase Plot: $u_1$ vs $u_2$ with Vector Field', fontsize=14)\n",
    "ax.set_xlabel('$u_1$', fontsize=12)\n",
    "ax.set_ylabel('$u_2$', fontsize=12)\n",
    "ax.grid(True)\n",
    "ax.set_facecolor('white')\n",
    "ax.legend()\n",
    "\n",
    "# Add colorbar for step size\n",
    "sm = plt.cm.ScalarMappable(cmap='inferno_r', norm=plt.Normalize(vmin=h_values.min(), vmax=h_values.max()))\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Step Size (h)', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.\n",
    "\n",
    "**Consider the Gaussian distribution $p(x_1, x_2, x_3)$ with mean $\\mu$ and covariance $\\mathbf{\\Sigma}$ being:**\n",
    "\n",
    "$$\\mathbf{\\mu} = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ \\end{bmatrix}, \\quad \\mathbf{\\Sigma} = \\begin{bmatrix} 3 & 1 & -1\\\\ 1 & 4 & 2\\\\ -1 & 2 & 3 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a.)\n",
    "\n",
    "**What is the marginal distribution $p(x_1, x_3)$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying proposition 3.7 (Marginal density of Gaussian) from the notes, we have that:\n",
    "$$\\tilde{\\mu} = \\begin{bmatrix} 1\\\\3\\end{bmatrix}, \\tilde{\\Sigma} = \\begin{bmatrix} 3 & -1\\\\ -1 & 3 \\end{bmatrix}$$\n",
    "\n",
    "In other words,\n",
    "$$ p(x_1, x_3) \\sim \\mathcal{N}(\\tilde{\\mu}, \\tilde{\\Sigma}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_gaussian(mu, Sigma, index):\n",
    "    \"\"\"\n",
    "    Returns the marginal mean vector and marginal covariance matrix for a subset of variables \n",
    "    from a multivariate Gaussian distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - mu (numpy.ndarray): Original mean vector of the multivariate Gaussian distribution.\n",
    "    - Sigma (numpy.ndarray): Original covariance matrix of the multivariate Gaussian distribution.\n",
    "    - index (array-like): Array or list of indices specifying the subset of variables for which \n",
    "                          the marginal distribution is required.\n",
    "    \n",
    "    Returns:\n",
    "    - marginal_mu (numpy.ndarray): 1-dimensional array representing the marginal mean vector \n",
    "                                   for the selected subset of variables.\n",
    "    - marginal_Sigma (numpy.ndarray): 2-dimensional array representing the marginal covariance \n",
    "                                      matrix for the selected subset of variables.\n",
    "    \"\"\"\n",
    "    marginal_mu = mu[index]                         # Partition the mean vector\n",
    "    marginal_Sigma = Sigma[np.ix_(index, index)]    # Partition the covariance matrix\n",
    "\n",
    "    return marginal_mu, marginal_Sigma\n",
    "\n",
    "mu = np.array([1, 2, 3])\n",
    "Sigma = np.array([[3, 1, -1], \n",
    "                  [1, 4, 2], \n",
    "                  [-1, 2, 3]])\n",
    "marginal_mu, marginal_Sigma = marginal_gaussian(mu, Sigma, [0,2])\n",
    "\n",
    "print(\"marginal mean:\\n\", marginal_mu)\n",
    "print('\\n')\n",
    "print(\"marginal covariance matrix:\\n\", marginal_Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b.)\n",
    "\n",
    "**What is the conditional distribution $p(x_1, x_3 | x_2 = 2)$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying proposition 3.8 (Conditional density of Gaussian) from the notes, we have that:\n",
    "\n",
    "$$\\mu^* = \\begin{bmatrix} \\begin{bmatrix} 1\\\\ 3 \\end{bmatrix}\\\\ 2\\end{bmatrix}$$\n",
    "\n",
    "$$\\Sigma^* = \\begin{bmatrix} \\begin{bmatrix} 3 & -1\\\\ -1 & 3 \\end{bmatrix} & \\begin{bmatrix} 1 \\\\ 2\\end{bmatrix}\\\\ \\begin{bmatrix} 1 & 2 \\end{bmatrix} & [4] \\end{bmatrix}$$\n",
    "\n",
    "where $\\mu^*$ and $\\Sigma^*$ are partitioned mean vector and covariance matrix respectively.\n",
    "\n",
    "Now, we know that:\n",
    "$$\\bar{\\mu} = \\begin{bmatrix} 1\\\\ 3 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 2\\end{bmatrix} \\cdot\\frac{1}{4} (2 - 2) = \\begin{bmatrix} 1\\\\ 3 \\end{bmatrix} = \\tilde{\\mu}$$\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        \\bar{\\Sigma} &= \\begin{bmatrix} 3 & -1\\\\ -1 & 3 \\end{bmatrix} - \\begin{bmatrix} 1 \\\\ 2\\end{bmatrix} \\cdot \\frac{1}{4} \\cdot \\begin{bmatrix} 1 & 2\\end{bmatrix}\\\\\n",
    "        \\\\\n",
    "                    &= \\begin{bmatrix} 3 & -1\\\\ -1 & 3 \\end{bmatrix} - \\begin{bmatrix} 1/4 & 1/2\\\\ 1/2 & 1\\end{bmatrix}\\\\\n",
    "        \\\\\n",
    "                    &= \\begin{bmatrix} 11/4 & -3/2\\\\ -3/2 & 2 \\end{bmatrix}\\\\   \n",
    "    \\end{split}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_gaussian(mu, Sigma, given_index, given_value):\n",
    "    \"\"\"\n",
    "    Computes the conditional mean vector and conditional covariance matrix for a multivariate\n",
    "    Gaussian distribution, given observed values for a subset of the variables.\n",
    "\n",
    "    Parameters:\n",
    "    - mu (numpy.ndarray): The original mean vector of the multivariate Gaussian distribution.\n",
    "    - Sigma (numpy.ndarray): The original covariance matrix of the multivariate Gaussian distribution.\n",
    "    - given_index (array-like): An array or list of indices specifying the subset of variables \n",
    "                                for which the values are given.\n",
    "    - given_value (array-like): An array or list of observed values corresponding to the indices \n",
    "                                specified in `given_index`.\n",
    "\n",
    "    Note: The lengths of `given_index` and `given_value` must match, as each index corresponds to \n",
    "          a given observed value.\n",
    "\n",
    "    Returns:\n",
    "    - conditional_mu (numpy.ndarray): A 1-dimensional array representing the conditional mean \n",
    "                                      vector for the remaining variables, conditioned on the \n",
    "                                      observed values.\n",
    "    - conditional_Sigma (numpy.ndarray): A 2-dimensional array representing the conditional \n",
    "                                         covariance matrix for the remaining variables.\n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    all_index = np.arange(n)\n",
    "\n",
    "    # Indices of the variables for which we are not given values (the ones to condition on)\n",
    "    not_given_index = np.setdiff1d(all_index, given_index)\n",
    "\n",
    "    # Partition the mean vector\n",
    "    mu_1 = mu[not_given_index]\n",
    "    mu_2 = mu[given_index]\n",
    "\n",
    "    # Partition the covariance matrix\n",
    "    Sigma_11 = Sigma[np.ix_(not_given_index, not_given_index)]\n",
    "    Sigma_12 = Sigma[np.ix_(not_given_index, given_index)]\n",
    "    Sigma_21 = Sigma[np.ix_(given_index, not_given_index)]\n",
    "    Sigma_22 = Sigma[np.ix_(given_index, given_index)]\n",
    "\n",
    "    # Compute the conditional mean and covariance\n",
    "    conditional_mu = mu_1 + Sigma_12 @ np.linalg.inv(Sigma_22) @ (given_value - mu_2)\n",
    "    conditional_Sigma = Sigma_11 - Sigma_12 @ np.linalg.inv(Sigma_22) @ Sigma_21\n",
    "\n",
    "    return conditional_mu, conditional_Sigma\n",
    "\n",
    "conditional_mu, conditional_Sigma = conditional_gaussian(mu, Sigma, \n",
    "                                                         given_index=[1], \n",
    "                                                         given_value=np.array([2]))\n",
    "\n",
    "print(\"conditional mean:\\n\", conditional_mu)\n",
    "print('\\n')\n",
    "print(\"conditional covariance matrix:\\n\", conditional_Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c.)\n",
    "\n",
    "**If you are allowed to change the entries in the covariance matrix, which entries will you change that will make the marginal distribution $p(x_1, x_3)$ and the conditional distribution $p(x_1, x_3 | x_2 = 2)$ become the same?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that as $x_2=2$ and $\\mu_2=2$ and therefore $x_2-\\mu_2=0$ which implies $\\tilde{\\mu} = \\bar{\\mu}$.\n",
    "\n",
    "For equating $\\tilde{\\Sigma} = \\bar{\\Sigma}$, we can do the following:\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        \\bar{\\Sigma} &= \\underbrace{\\begin{bmatrix} 3 & -1\\\\ -1 & 3 \\end{bmatrix}}_{=\\tilde{\\Sigma}} - \\underbrace{\\mathbf{\\Sigma_{12}}\\mathbf{\\Sigma_{22}^{-1}}\\mathbf{\\Sigma_{21}}}_{=0}\\\\\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "We can achieve this by equation $\\mathbf{\\Sigma_{12}}=\\begin{bmatrix} 0\\\\ 0 \\end{bmatrix}$ and $\\mathbf{\\Sigma_{21}}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}$, i.e.,\n",
    "$$\\mathbf{\\Sigma} = \\begin{bmatrix} 3 & 0 & -1\\\\ 0 & 4 & 0\\\\ -1 & 0 & 3 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Sigma = np.array([[3, 0, -1], \n",
    "                      [0, 4, 0], \n",
    "                      [-1, 0, 3]])\n",
    "\n",
    "# Compute the marginal and conditional distributions for x1, x3 given x2\n",
    "marginal_mu, marginal_covariance = marginal_gaussian(mu=mu, Sigma=new_Sigma, index=[0, 2])\n",
    "conditional_mu, conditional_covariance = conditional_gaussian(mu=mu, Sigma=new_Sigma, \n",
    "                                                              given_index=[1], given_value=np.array([2]))\n",
    "\n",
    "# Create a grid for plotting\n",
    "x1, x3 = np.mgrid[-10:10:.1, -10:10:.1]\n",
    "pos = np.dstack((x1, x3))\n",
    "\n",
    "# Define the distributions\n",
    "rv_marginal = multivariate_normal(marginal_mu, marginal_covariance)\n",
    "rv_conditional = multivariate_normal(conditional_mu, conditional_covariance)\n",
    "\n",
    "# Generate random samples from the marginal and conditional distributions for overlaying scatter points\n",
    "samples_marginal = np.random.multivariate_normal(marginal_mu, marginal_covariance, size=500)\n",
    "samples_conditional = np.random.multivariate_normal(conditional_mu, conditional_covariance, size=500)\n",
    "\n",
    "# Update the plot to have a white background\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6), facecolor='white')\n",
    "\n",
    "# Marginal distribution (x1, x3)\n",
    "ax[0].contour(x1, x3, rv_marginal.pdf(pos), levels=10, cmap='inferno_r')\n",
    "ax[0].scatter(samples_marginal[:, 0], samples_marginal[:, 1], alpha=0.3, color='grey', s=5)\n",
    "ax[0].set_title('Marginal Gaussian: $p(x_1, x_3)$')\n",
    "ax[0].set_facecolor('white')\n",
    "ax[0].grid(True, color='black', alpha=0.1)\n",
    "\n",
    "# Conditional distribution (x1, x3 | x2 = 2)\n",
    "ax[1].contour(x1, x3, rv_conditional.pdf(pos), levels=10, cmap='inferno_r')\n",
    "ax[1].scatter(samples_conditional[:, 0], samples_conditional[:, 1], alpha=0.3, color='grey', s=5)\n",
    "ax[1].set_title('Conditional Gaussian: $p(x_1, x_3 | x_2 = 2)$')\n",
    "ax[1].set_facecolor('white')\n",
    "ax[1].grid(True, color='black', alpha=0.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.\n",
    "\n",
    "**Devise a Monte Carlo method to compute $e = 2.71828...$, and conduct numerical experiments to illustrate the accuracy as a function of the number of samples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presented below is a novel approach integrating Monte Carlo simulation with binary search to approximate Euler's number, $e$.\n",
    "\n",
    "Consider the following relationship:\n",
    "$$\\int_{1}^{e} \\frac{1}{x}\\;dx = \\bigg[\\log(x)\\bigg]_{1}^{e} = 1$$\n",
    "\n",
    "Our objective is to estimate the upper limit of the integral such that the definite integral evaluates to 1.\n",
    "\n",
    "To evaluate this integral using a Monte Carlo approach, we generate  uniformly distributed samples from the interval $[1, \\text{mid}]$, where $\\text{mid}=(\\text{low}+\\text{high})/2$. We then explicitly compute the expectation as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        \\mathbb{E}\\bigg[\\frac{1}{X}\\bigg] &= \\int_{1}^{\\text{mid}} \\frac{1}{x} \\cdot \\underbrace{\\frac{1}{\\text{mid}-1}}_{\\text{pdf of uniform $[0,\\text{mid}]$}}\\;dx\\\\\n",
    "        \\\\\n",
    "        \\mathbb{E}\\bigg[\\frac{1}{X}\\bigg] &= \\frac{1}{\\text{mid}-1} \\int_{1}^{\\text{mid}} \\frac{1}{x}\\;dx\\\\\n",
    "        \\\\\n",
    "        \\mathbb{E}\\bigg[\\frac{1}{X}\\bigg] &= \\frac{1}{\\text{mid}-1} \\bigg[\\text{log}(x)\\bigg]_{1}^{\\text{mid}}\\\\\n",
    "        \\\\\n",
    "        \\mathbb{E}\\bigg[\\frac{1}{X}\\bigg] &= \\frac{\\text{log}(\\text{mid})}{\\text{mid}-1}\\\\\n",
    "        \\\\\n",
    "        \\underbrace{\\mathbb{E}\\bigg[\\frac{1}{X}\\bigg] \\cdot (\\text{mid}-1)}_{= \\xi} &= \\text{log}(\\text{mid})\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Our goal is to determine the value of $\\text{mid}$ such that $\\xi=1$, i.e.,\n",
    "$$ \\xi = 1 \\iff \\mathbb{E}[1/X] \\cdot (\\text{mid}-1) = 1 \\iff \\text{log}(\\text{mid}) = 1 \\iff \\text{mid}=e$$\n",
    "\n",
    "To achieve this, we iteratively adjust the bounds using a binary search algorithm. We start with $\\text{low}=1$ and $\\text{high}=4$. Abstractly, $\\text{low}$ and $\\text{high}$ can be any real number which we know for sure is lesser than and greater than $e$.\n",
    "\n",
    "* If the estimated value $\\xi$ is greater than 1, we update the upper bound to $\\text{high}=\\text{mid}$. \n",
    "\n",
    "* If the estimated value $\\xi$ is lesser than 1, we update the lower bound to $\\text{low}=\\text{mid}$. \n",
    "\n",
    "This process is repeated until $|\\text{high} - \\text{low}| < 0.01$, providing an estimate for $e$. It is evident that that the binary search converges more accurately depending on how accurate the estimate $\\xi$ is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_estimate_xi(M, mid):\n",
    "    \"\"\"\n",
    "    Perform a Monte Carlo estimation of xi (the inverse of the uniform distribution mean).\n",
    "\n",
    "    Parameters:\n",
    "    - M (int): The number of Monte Carlo samples to draw from a uniform distribution.\n",
    "    - mid (float): The upper bound of the uniform distribution (lower bound is fixed at 1).\n",
    "\n",
    "    Returns:\n",
    "    - (float): The Monte Carlo estimate of xi, calculated as the mean of 1 divided by the uniform samples, \n",
    "               scaled by the range (mid - 1).\n",
    "    \"\"\"\n",
    "    return np.mean(1 / np.random.uniform(low=1, high=mid, size=M)) * (mid - 1)\n",
    "\n",
    "def binary_search_for_e(M, low=1, high=4, tolerance=0.01):\n",
    "    \"\"\"\n",
    "    Use a binary search to estimate the value of 'e' by solving the equation for xi = 1 \n",
    "    using Monte Carlo estimation.\n",
    "\n",
    "    Parameters:\n",
    "    - M (int): The number of Monte Carlo samples to use in the estimation at each step.\n",
    "    - low (float): The initial lower bound for the binary search (default is 1).\n",
    "    - high (float): The initial upper bound for the binary search (default is 4).\n",
    "    - tolerance (float): The stopping criterion for the binary search (default is 0.01).\n",
    "\n",
    "    Returns:\n",
    "    - (float): The estimated value of 'e' (the point where xi = 1) after performing binary search.\n",
    "    \"\"\"\n",
    "    while np.abs(high - low) > tolerance:\n",
    "        mid = (low + high) / 2\n",
    "        xi = monte_carlo_estimate_xi(M=M, mid=mid)\n",
    "        if xi > 1.0:\n",
    "            high = mid\n",
    "        else:\n",
    "            low = mid\n",
    "    return (low + high) / 2\n",
    "\n",
    "def compute_estimates(sample_size):\n",
    "    \"\"\"\n",
    "    Compute multiple estimates of 'e' using the binary search method with Monte Carlo estimation.\n",
    "\n",
    "    Parameters:\n",
    "    - sample_size (int): The number of Monte Carlo samples to use in each binary search.\n",
    "\n",
    "    Returns:\n",
    "    - (float): The mean of the estimated values of 'e' across multiple simulations.\n",
    "    - (float): The standard deviation of the estimated values of 'e' across multiple simulations.\n",
    "    \"\"\"\n",
    "    estimates = [binary_search_for_e(sample_size) for _ in range(100)]\n",
    "    return np.mean(estimates), np.std(estimates)\n",
    "\n",
    "# Generate more points for sample sizes using linear spacing\n",
    "sample_sizes = np.arange(1, 20)  # Linearly spaced sample sizes for more data points\n",
    "results = Parallel(n_jobs=-1)(delayed(compute_estimates)(M) for M in sample_sizes)\n",
    "\n",
    "approx_soln = np.asarray([results[i][0] for i in range(len(results))])\n",
    "df = pd.DataFrame({'sample_size': sample_sizes,  \n",
    "                   'approx_soln': approx_soln, \n",
    "                   'abs_diff': np.abs(np.exp(1) - approx_soln)})\n",
    "\n",
    "df.style.background_gradient(cmap='inferno', subset=['sample_size', 'approx_soln', 'abs_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a curve of the form a/x + b to the standard errors\n",
    "def inverse_fit(x, a, b):\n",
    "    \"\"\"\n",
    "    A function to model the inverse relationship for curve fitting of the form a/x + b.\n",
    "\n",
    "    This function is used to fit a curve to data points, where the relationship between \n",
    "    the independent variable x and the dependent variable follows an inverse pattern.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray or float): The independent variable (e.g., sample sizes).\n",
    "    - a (float): The parameter representing the coefficient for the inverse term (a/x).\n",
    "    - b (float): The parameter representing the intercept (constant term).\n",
    "\n",
    "    Returns:\n",
    "    - (numpy.ndarray or float): The modeled values a/x + b for the given x, a, and b.\n",
    "    \"\"\"\n",
    "    return a / x + b\n",
    "\n",
    "# Generate more points for sample sizes using linear spacing\n",
    "sample_sizes = np.arange(10, 10000, 30)  # Linearly spaced sample sizes for more data points\n",
    "results = Parallel(n_jobs=-1)(delayed(compute_estimates)(M) for M in sample_sizes)\n",
    "\n",
    "# Extract e_estimates and standard_errors from results\n",
    "e_estimates, standard_errors = zip(*results)\n",
    "\n",
    "# Create subplots for visualization\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(15, 6), facecolor='white')\n",
    "\n",
    "# Scatter plot: Monte Carlo estimate of e vs. sample size\n",
    "sc0 = ax0.scatter(sample_sizes, \n",
    "                  e_estimates,\n",
    "                  c=e_estimates,\n",
    "                  cmap='inferno',\n",
    "                  marker=\"o\",\n",
    "                  alpha=0.6)\n",
    "\n",
    "ax0.axhline(y=np.exp(1), color=\"red\", linestyle=\"--\", label='True Eulers number $e$')\n",
    "ax0.set_title(\"Monte Carlo Estimate of $e$ vs. Sample Size\", fontsize=12)\n",
    "ax0.set_xlabel(\"Sample Size\", fontsize=10)\n",
    "ax0.set_ylabel(\"Estimated $e$\", fontsize=10)\n",
    "ax0.grid(True, color=\"black\", alpha=0.1)\n",
    "ax0.set_facecolor('white')\n",
    "ax0.legend()\n",
    "\n",
    "# Using scipy's curve_fit to find optimum parameters a and b\n",
    "popt, pcov = curve_fit(inverse_fit, sample_sizes, standard_errors)\n",
    "\n",
    "# Plotting the fitted 1/x trend line\n",
    "ax1.plot(sample_sizes, inverse_fit(sample_sizes, *popt), \n",
    "         'r--', label=f'Fit: {popt[0]:.2e}/x + {popt[1]:.2e}')\n",
    "\n",
    "# Scatter plot: Standard error vs. sample size\n",
    "sc1 = ax1.scatter(sample_sizes, \n",
    "                  standard_errors,\n",
    "                  c=standard_errors,\n",
    "                  cmap='inferno',\n",
    "                  marker=\"o\",\n",
    "                  alpha=0.3)\n",
    "\n",
    "ax1.set_title(\"Standard Error vs. Sample Size\", fontsize=12)\n",
    "ax1.set_xlabel(\"Sample Size\", fontsize=10)\n",
    "ax1.set_ylabel(\"Standard Error\", fontsize=10)\n",
    "ax1.grid(True, color=\"black\", alpha=0.1)\n",
    "ax1.set_facecolor('white')\n",
    "ax1.legend()\n",
    "\n",
    "plt.colorbar(sc0, ax=ax0, label='Estimated e value')\n",
    "plt.colorbar(sc1, ax=ax1, label='Standard error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sizes to test\n",
    "sample_sizes = range(1, 10000, 1000)\n",
    "\n",
    "# Store mean estimates and absolute errors\n",
    "mean_estimates = []\n",
    "absolute_errors = []\n",
    "\n",
    "# Run experiments for different sample sizes\n",
    "for sample_size in sample_sizes:\n",
    "    mean_estimate, _ = compute_estimates(sample_size)\n",
    "    mean_estimates.append(mean_estimate)\n",
    "    absolute_errors.append(np.abs(mean_estimate - np.exp(1)))\n",
    "\n",
    "# Create figure with custom layout\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "fig.patch.set_facecolor('white')  # Set the figure background to white\n",
    "ax.set_facecolor('white')         # Set the axis background to white\n",
    "\n",
    "ax.plot(sample_sizes, absolute_errors, marker='o', color='b', label='Absolute Error')\n",
    "ax.set_xscale('log')  # Log scale for better visualization\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Number of Samples (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Absolute Error (log scale)', fontsize=12)\n",
    "ax.set_title('Accuracy of Monte Carlo Estimation of $e$ as a Function of Number of Samples', fontsize=14)\n",
    "ax.grid(True, color='black', alpha=0.1)\n",
    "ax.legend()\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5.\n",
    "\n",
    "**Show an SDE (and the associated parameters), which simultaneously satisfy the following two conditions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that, the linear Gaussian SDE is of the form:\n",
    "$$dX_t = (-aX_t + f)\\;dt + \\sigma \\; dW_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a.)\n",
    "\n",
    "**Starting from any finite initial value, the mean of the SDE will eventually converge to zero; and**\n",
    "\n",
    "The long-term mean of an SDE will be:\n",
    "$$\\mu_{\\infty} = \\frac{f}{a}$$\n",
    "\n",
    "For $f/a = 0$, it must be that $f=0$ and $a \\neq 0$, i.e.,\n",
    "\n",
    "$$dX_t = -aX_t\\;dt + \\sigma\\;dW_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b.)\n",
    "\n",
    "**The variance of the SDE will blow up when time t → ∞.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The long-term variance of an SDE will be:\n",
    "$$\\text{Var}_{\\infty} = \\frac{\\sigma^2}{a}$$\n",
    "\n",
    "For $\\sigma^2/a = \\infty$ and $a \\neq 0$\n",
    "\n",
    "This is possible if our $\\sigma(t) = (\\sigma_0)^2 \\cdot t$ where $0<\\sigma_0$, i.e., the diffusion term is time-dependent. \n",
    "\n",
    "Another way of interpreting this would be that the magnitude $\\sigma(t) \\cdot dW_t = (\\sigma_0)^2 \\cdot t\\;dW_t$ increases as $t$ increases.\n",
    "\n",
    "Arbitrarily, our SDE is as follows:\n",
    "$$dX_t = (-a)X_t\\;dt + (\\sigma_0)^2 \\cdot t\\;dW_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the short-run, we have the following parameters:\n",
    "* $a$: 0.1\n",
    "* $T$: 10\n",
    "* $N$: 1000\n",
    "* $X_0$: 1\n",
    "* $\\sigma_0$: 1\n",
    "\n",
    "The associated SDE is:\n",
    "$$dX_t = -(0.1) X_t\\;dt + t\\;dW_t, X_0=1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dXt_conditional(a, Xt, dt, sigma, dWt):\n",
    "    \"\"\"\n",
    "    SDE function for the time derivative of Xt: dX_t = -a X_t dt + sigma dW_t\n",
    "    \n",
    "    Parameters:\n",
    "    - a (float): The drift coefficient, representing the strength of the mean-reverting term (-a X_t).\n",
    "    - Xt (float): The current value of the process Xt.\n",
    "    - dt (float): The time step size.\n",
    "    - sigma (float): The time-dependent volatility (diffusion) coefficient.\n",
    "    - dWt (float): The Wiener process increment (random term).\n",
    "    \n",
    "    Returns:\n",
    "    - (float): The time derivative of Xt based on the current value, time step size, and random increment.\n",
    "    \"\"\"\n",
    "    return -a * Xt * dt + sigma * dWt\n",
    "\n",
    "def euler_maruyama_conditional(a, T, N, X0, sigma_0):\n",
    "    \"\"\"\n",
    "    Euler-Maruyama method to numerically solve a stochastic differential equation (SDE):\n",
    "    dX_t = -a X_t dt + sigma(t) dW_t, X_0 = X0.\n",
    "    \n",
    "    In this SDE, the drift term tends to 0 as the process evolves, and the variance grows without bound.\n",
    "    \n",
    "    Parameters:\n",
    "    - a (float): The drift coefficient in the SDE (mean-reverting strength).\n",
    "    - T (float): The total simulation time.\n",
    "    - N (int): The number of time steps.\n",
    "    - X0 (float): The initial value of the process Xt at time t=0.\n",
    "    - sigma_0 (float): The initial diffusion coefficient. The diffusion (volatility) grows with time as sigma_0 * sqrt(t).\n",
    "    \n",
    "    Returns:\n",
    "    - t (numpy.ndarray): Array of time points from 0 to T.\n",
    "    - Xt (numpy.ndarray): Array of simulated values of the process Xt at each time step.\n",
    "    \"\"\"\n",
    "    dt = T / N\n",
    "    t = np.linspace(0, T, N+1)\n",
    "    \n",
    "    # Initialize the array for the solution\n",
    "    Xt = np.zeros(N+1)\n",
    "    Xt[0] = X0  # Initial condition\n",
    "    \n",
    "    # Simulate the process using Euler-Maruyama\n",
    "    for i in range(N):\n",
    "        dWt = np.random.normal(0, np.sqrt(dt))  # Wiener process increment\n",
    "        sigma_t = (sigma_0**2) * t[i]  # Time-dependent diffusion\n",
    "        Xt[i+1] = Xt[i] + dXt_conditional(a=a, Xt=Xt[i], dt=dt, sigma=sigma_t, dWt=dWt)\n",
    "    \n",
    "    return t, Xt\n",
    "\n",
    "# Run simulation and collect the respective t and Xt values\n",
    "a = 0.1             # Multiplier for shift-term\n",
    "T = 10              # Small total time\n",
    "N = 1000            # Number of steps\n",
    "X0 = 1              # Initial condition\n",
    "sigma_0 = 1         # Multiplier drift-Term\n",
    "t, Xt = euler_maruyama_conditional(a=a, \n",
    "                                   T=T, \n",
    "                                   N=N, \n",
    "                                   X0=X0, \n",
    "                                   sigma_0=sigma_0)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_xt, std_xt = statistics_TS(Xt)\n",
    "\n",
    "# Create figure with custom layout\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "fig.patch.set_facecolor('white')  # Set the figure background to white\n",
    "ax.set_facecolor('white')         # Set the axis background to white\n",
    "\n",
    "ax.plot(t, Xt, alpha=0.5, color='black', label='Euler-Maruyama Simulation', linewidth=1)\n",
    "ax.axhline(y=mean_xt-std_xt, color=\"orange\", linestyle=\"--\", label=f\"standard deviation bands\")\n",
    "ax.axhline(y=mean_xt, color=\"black\", linestyle=\"--\", label=f\"Mean = {mean_xt:.4f}\")\n",
    "ax.axhline(y=mean_xt+std_xt, color=\"orange\", linestyle=\"--\")\n",
    "ax.set_title('Short-time Euler-Maruyama Simulation\\n$dX_t = -(0.1) \\cdot X_t \\\\; dt + (1)^2 \\\\cdot t \\\\; dW_t$, $X_0=1$')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('X(t)')\n",
    "ax.grid(True, color='black', alpha=0.1)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the long-run, we have the following parameters:\n",
    "* $a$: 0.1\n",
    "* $T$: 100000\n",
    "* $N$: 10000000\n",
    "* $X_0$: 1\n",
    "* $\\sigma_0$: 0.01\n",
    "\n",
    "The associated SDE is:\n",
    "$$dX_t = -(0.1) X_t\\;dt + (0.01)^2 \\cdot t\\;dW_t, X_0=1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, Xt = euler_maruyama_conditional(a=0.1, T=1000000, N=10000000, X0=1, sigma_0=0.01)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_xt, std_xt = statistics_TS(Xt)\n",
    "\n",
    "# Create figure with custom layout\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Create a GridSpec layout with different column widths and minimal spacing\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[4, 1], wspace=0.05)\n",
    "\n",
    "# Left subplot: Time series (larger)\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.plot(t, Xt, alpha=0.5, color='black', label='Euler-Maruyama Simulation', linewidth=1)\n",
    "ax1.axhline(y=mean_xt-std_xt, color=\"orange\", linestyle=\"--\", label=f\"standard deviation bands\")\n",
    "ax1.axhline(y=mean_xt, color=\"black\", linestyle=\"--\", label=f\"Mean = {mean_xt:.4f}\")\n",
    "ax1.axhline(y=mean_xt+std_xt, color=\"orange\", linestyle=\"--\")\n",
    "ax1.set_title('Long-time Euler-Maruyama Simulation\\n$dX_t = -(0.1) \\\\cdot X_t \\\\; dt + (0.01)^2 \\\\cdot t \\\\; dW_t$, $X_0=1$', pad=10)\n",
    "ax1.set_xlabel('Time', fontsize=12)\n",
    "ax1.set_ylabel('$X_t$', fontsize=12)\n",
    "ax1.set_facecolor('white')\n",
    "ax1.grid(True, color='black', alpha=0.1)\n",
    "ax1.legend()\n",
    "\n",
    "# Right subplot: Rotated histogram\n",
    "ax2 = plt.subplot(gs[1])\n",
    "# Create horizontal histogram\n",
    "ax2.hist(Xt, bins=25, density=True, orientation='horizontal',\n",
    "         alpha=0.5, color='grey', label='Simulation')\n",
    "\n",
    "y = np.linspace(-750, 750, 100)\n",
    "\n",
    "pdf2 = norm.pdf(y, mean_xt, std_xt)\n",
    "ax2.plot(pdf2, y, alpha=0.5, color=\"blue\",\n",
    "         linestyle='--', label=f'Estimated: N({np.round(mean_xt, 2)}, {np.round(std_xt, 2)})')\n",
    "\n",
    "ax2.axhline(y=mean_xt+std_xt, color=\"orange\", linestyle=\"--\", label=\"standard deviation bands\")\n",
    "ax2.axhline(y=mean_xt-std_xt, color=\"orange\", linestyle=\"--\")\n",
    "ax2.axhline(y=mean_xt, color=\"black\", linestyle='--', label='mean')\n",
    "ax2.set_xlim(0, 0.006)\n",
    "ax2.set_title('Density Distribution')\n",
    "ax2.set_xlabel('Density')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_facecolor('white')\n",
    "ax2.grid(True, color='black', alpha=0.1)\n",
    "ax2.legend()\n",
    "\n",
    "ylim = ax1.get_ylim()\n",
    "ax2.set_ylim(ylim)\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
